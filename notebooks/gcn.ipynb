{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid, MNISTSuperpixels\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, ChebConv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Mnist'\n",
    "path = '../data/geometric/MNIST'\n",
    "dataset = MNISTSuperpixels(path, dataset, T.Distance())\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "# dataset = Planetoid(path, dataset, T.NormalizeFeatures())\n",
    "#data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(dataset.num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = GCNConv(dataset.num_features, 16, improved=False)\n",
    "#         self.conv2 = GCNConv(16, dataset.num_classes, improved=False)\n",
    "#         # self.conv1 = ChebConv(data.num_features, 16, K=2)\n",
    "#         # self.conv2 = ChebConv(16, data.num_features, K=2)\n",
    "        \n",
    "#     def forward(self):\n",
    "#         x, edge_index = data.x, data.edge_index\n",
    "#         x = F.relu(self.conv1(x, edge_index))\n",
    "#         x = F.dropout(x, training=self.training)\n",
    "#         x = self.conv2(x, edge_index)\n",
    "#         return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_features, 16, improved=False)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes, improved=False)\n",
    "        # self.conv1 = ChebConv(data.num_features, 16, K=2)\n",
    "        # self.conv2 = ChebConv(16, data.num_features, K=2)\n",
    "        \n",
    "        self.deconv1 = GCNConv(dataset.num_classes, 16, improved=False)\n",
    "        self.deconv2 = GCNConv(16, dataset.num_features, improved=False)\n",
    "        \n",
    "    def encode(self, x, edge_index):\n",
    "        \n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return x, edge_index\n",
    "    \n",
    "    def decode(self, x, edge_index):\n",
    "        x = F.relu(self.deconv1(x, edge_index))\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        x = self.deconv2(x, edge_index)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        \n",
    "    def forward(self):\n",
    "        \n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        encoded, idx = self.encode(x, edge_index)\n",
    "        decoded = self.decode(encoded, idx)\n",
    "        \n",
    "        return decoded\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pyro Example: http://pyro.ai/examples/vae.html\n",
    "# VAE example with sampling code \n",
    "# https://wiseodd.github.io/techblog/2017/01/24/vae-pytorch/\n",
    "# https://github.com/wiseodd/generative-models/blob/master/VAE/vanilla_vae/vae_pytorch.py\n",
    "    \n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / np.sqrt(in_dim / 2.)\n",
    "        \n",
    "    return Variable(torch.randn(*size) * xavier_stddev, requires_grad=True)\n",
    "\n",
    "\n",
    "Wxh = xavier_init(size=[X_dim, h_dim])\n",
    "bxh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Whz_mu = xavier_init(size=[h_dim, Z_dim])\n",
    "bhz_mu = Variable(torch.zeros(Z_dim), requires_grad=True)\n",
    "\n",
    "Whz_var = xavier_init(size=[h_dim, Z_dim])\n",
    "bhz_var = Variable(torch.zeros(Z_dim), requires_grad=True)\n",
    "\n",
    "\n",
    "def Q(X):\n",
    "    h = nn.relu(X @ Wxh + bxh.repeat(X.size(0), 1))\n",
    "    z_mu = h @ Whz_mu + bhz_mu.repeat(h.size(0), 1)\n",
    "    z_var = h @ Whz_var + bhz_var.repeat(h.size(0), 1)\n",
    "    return z_mu, z_var\n",
    "\n",
    "def sample_z(mu, log_var):\n",
    "    # Using reparameterization trick to sample from a gaussian\n",
    "    eps = Variable(torch.randn(mb_size, Z_dim))\n",
    "    return mu + torch.exp(log_var / 2) * eps\n",
    "\n",
    "Wzh = xavier_init(size=[Z_dim, h_dim])\n",
    "bzh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Whx = xavier_init(size=[h_dim, X_dim])\n",
    "bhx = Variable(torch.zeros(X_dim), requires_grad=True)\n",
    "\n",
    "\n",
    "def P(z):\n",
    "    h = nn.relu(z @ Wzh + bzh.repeat(z.size(0), 1))\n",
    "    X = nn.sigmoid(h @ Whx + bhx.repeat(h.size(0), 1))\n",
    "    return X\n",
    "\n",
    "\n",
    "solver = optim.Adam(params, lr=lr)\n",
    "\n",
    "for it in range(100000):\n",
    "    X, _ = mnist.train.next_batch(mb_size)\n",
    "    X = Variable(torch.from_numpy(X))\n",
    "\n",
    "    # Forward\n",
    "    z_mu, z_var = Q(X)\n",
    "    z = sample_z(z_mu, z_var)\n",
    "    X_sample = P(z)\n",
    "\n",
    "    # Loss\n",
    "    recon_loss = nn.binary_cross_entropy(X_sample, X, size_average=False) / mb_size\n",
    "    kl_loss = torch.mean(0.5 * torch.sum(torch.exp(z_var) + z_mu**2 - 1. - z_var, 1))\n",
    "    loss = recon_loss + kl_loss\n",
    "\n",
    "    # Backward\n",
    "    loss.backward()\n",
    "\n",
    "    # Update\n",
    "    solver.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "numEpochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 step:  0 train loss:  0.17328667640686035\n",
      "Epoch:  1 step:  10 train loss:  0.09969157725572586\n",
      "Epoch:  2 step:  0 train loss:  0.0971202403306961\n",
      "Epoch:  2 step:  10 train loss:  0.0872308686375618\n",
      "Epoch:  3 step:  0 train loss:  0.0834479033946991\n",
      "Epoch:  3 step:  10 train loss:  0.08151454478502274\n",
      "Epoch:  4 step:  0 train loss:  0.0771080031991005\n",
      "Epoch:  4 step:  10 train loss:  0.0720825120806694\n",
      "Epoch:  5 step:  0 train loss:  0.0752023234963417\n",
      "Epoch:  5 step:  10 train loss:  0.07494006305932999\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, numEpochs+1):\n",
    "    for step, batch in enumerate(loader):\n",
    "        if step < 20:\n",
    "            \n",
    "            data = batch.to(device)\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = nn.MSELoss()\n",
    "#             loss = nn.BCELoss()\n",
    "\n",
    "            target = data\n",
    "            output = loss(model(), target['x'])\n",
    "            output.backward()\n",
    "\n",
    "\n",
    "#           F.binary_cross_entropy(model(), target['x']).backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            if step % 10 == 0:\n",
    "                print('Epoch: ', epoch, 'step: ', step, 'train loss: ', output.item())\n",
    "        else: \n",
    "            break\n",
    "    \n",
    "\n",
    "#             # plotting decoded image (second row)\n",
    "#             _, decoded_data = autoencoder(view_data)\n",
    "#             for i in range(N_TEST_IMG):\n",
    "#                 a[1][i].clear()\n",
    "#                 a[1][i].imshow(np.reshape(decoded_data.data.numpy()[i], (28, 28)), cmap='gray')\n",
    "#                 a[1][i].set_xticks(()); a[1][i].set_yticks(())\n",
    "#             plt.draw(); plt.pause(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train():\n",
    "#     model.train()\n",
    "#     optimizer.zero_grad()\n",
    "    \n",
    "#     F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()\n",
    "    \n",
    "#     loss = nn.BCELoss()\n",
    "#     target = data.x[data.train_mask]\n",
    "#     print(target)\n",
    "#     print(model()[data.train_mask])\n",
    "    \n",
    "#     output = loss(model()[data.train_mask], target)\n",
    "#     output.backward()\n",
    "    \n",
    "    \n",
    "#     torch.nn.BCELoss(model()[data.train_mask], data.x[data.train_mask]).backward()\n",
    "    \n",
    "#     optimizer.step()\n",
    "\n",
    "# def test():\n",
    "#     model.eval()\n",
    "#     logits, accs = model(), []\n",
    "#     for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "#         pred = logits[mask].max(1)[1]\n",
    "#         acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
    "#         accs.append(acc)\n",
    "#     return accs\n",
    "\n",
    "# best_val_acc = test_acc = 0\n",
    "# for epoch in range(1, 50):\n",
    "#     train()\n",
    "#     train_acc, val_acc, tmp_test_acc = test()\n",
    "#     if val_acc > best_val_acc:\n",
    "#         best_val_acc = val_acc\n",
    "#         test_acc = tmp_test_acc\n",
    "#     log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
    "#     print(log.format(epoch, train_acc, best_val_acc, test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "print(min(target['x']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
