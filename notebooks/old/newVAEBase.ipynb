{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from IPython import embed\n",
    "import os.path as osp\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy as sp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Normal\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, ChebConv  # noqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Cora'\n",
    "path = path = '../data/geometric/CORA'\n",
    "dataset = Planetoid(path, dataset, T.NormalizeFeatures())\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GCN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(GCN, self).__init__()\n",
    "#         self.conv1 = GCNConv(dataset.num_features, 16, improved=False)\n",
    "#         self.conv2 = GCNConv(16, dataset.num_classes, improved=False)\n",
    "\n",
    "#     def forward(self):\n",
    "#         x, edge_index = data.x, data.edge_index\n",
    "#         x = F.relu(self.conv1(x, edge_index))\n",
    "#         x = F.dropout(x, training=self.training)\n",
    "#         x = self.conv2(x, edge_index)\n",
    "        \n",
    "#         return F.log_softmax(x, dim=1)\n",
    "    \n",
    "# class Encoder(nn.Module):\n",
    "#     def __init__(self, n_feat, z_dim, hidden_dim):\n",
    "#         super(Encoder, self).__init__()\n",
    "#         self.conv1 = GCNConv(n_feat, 16, improved=False)\n",
    "#         self.conv2 = GCNConv(16, dataset.num_classes, improved=False)\n",
    "        \n",
    "#         self.gc1 = GCNConv(n_feat, hidden_dim)\n",
    "#         self.gc2_mu = GCNConv(hidden_dim, z_dim)\n",
    "#         self.gc2_sig = GCNConv(hidden_dim, z_dim)\n",
    "        \n",
    "# #         Setup for non-linearities\n",
    "#         self.softplus = nn.Softplus()\n",
    "#         self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "#     def forward(self):\n",
    "# #         x, edge_index = data.x, data.edge_index\n",
    "# #         x = F.relu(self.conv1(x, edge_index))\n",
    "# #         x = F.dropout(x, training=self.training)\n",
    "# #         x = self.conv2(x, edge_index)\n",
    "        \n",
    "# #         return F.log_softmax(x, dim=1)\n",
    "\n",
    "#         hidden = self.softplus(self.gc1(x, adj))\n",
    "#         z_loc = self.gc2_mu(hidden, adj)\n",
    "#         z_scale = torch.exp(self.gc2_sig(hidden, adj))\n",
    "\n",
    "#         return z_loc, z_scale\n",
    "\n",
    "    \n",
    "# class Decoder(nn.Module):\n",
    "#     def __init__(self, z_dim, hidden_dim):\n",
    "#         super(Decoder, self).__init__()\n",
    "#         # setup the two linear transformations used for the decoder \n",
    "#         self.fc1 = nn.Linear(z_dim, hidden_dim)\n",
    "#         self.fc21 = nn.Linear(hidden_dim, 10)\n",
    "#         # setup the non-linearities\n",
    "#         self.softplus = nn.Softplus()\n",
    "\n",
    "#     def forward(self, z):\n",
    "#         # define the forward computation on the latent z\n",
    "#         # first compute the hidden units\n",
    "\n",
    "#         hidden = self.softplus(self.fc1(z))\n",
    "# #         loc_img = torch.sigmoid(self.fc21(hidden))\n",
    "# #         return loc_img\n",
    "\n",
    "#         return F.log_softmax(self.fc21(hidden))\n",
    "    \n",
    "# class VAE(nn.Module):\n",
    "#     def __init__(self, z_dim=16, hidden_dim=400, use_cuda=False):\n",
    "#         super(VAE, self).__init__()\n",
    "\n",
    "#         self.encoder = Encoder(dataset.num_features, z_dim, hidden_dim)\n",
    "#         self.decoder = Decoder(z_dim, hidden_dim)\n",
    "\n",
    "#         if use_cuda:\n",
    "#             self.cuda()\n",
    "            \n",
    "#         self.use_cuda = use_cuda\n",
    "#         self.z_dim = z_dim\n",
    "        \n",
    "#     def forward(self):\n",
    "#         z_loc, z_scale = self.encoder.forward()\n",
    "#         z = Normal(z_loc, z_scale)\n",
    "        \n",
    "#         out = self.decoder.forward(z)\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, num_features, z_dim, hidden_dim, dropout, use_cuda=False):\n",
    "        super(VAE, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, z_dim, improved=False)\n",
    "        self.conv2 = GCNConv(z_dim, hidden_dim, improved=False)\n",
    "        self.decoder = InnerProductDecoder(dropout, activation=lambda x:x)\n",
    "        \n",
    "#         self.gc1 = GCNConv(n_feat, hidden_dim)\n",
    "#         self.gc2_mu = GCNConv(hidden_dim, z_dim)\n",
    "#         self.gc2_sig = GCNConv(hidden_dim, z_dim)\n",
    "\n",
    "    def encode(self, x, adj):\n",
    "        hidden = self.conv1(x, adj)\n",
    "        return self.conv2(hidden, adj)\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(logvar)\n",
    "            epsilon = torch.rand_like(mu)\n",
    "        else:\n",
    "            return mu\n",
    "        \n",
    "    def forward(self, x, adj):\n",
    "        mu, logvar = self.enode(x, adj)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decoder(z), mu, logvar\n",
    "            \n",
    "\n",
    "class InnerProductDecoder(nn.Module):\n",
    "    \"\"\"Decoder for using inner product for prediction.\n",
    "       https://github.com/zfjsail/gae-pytorch/blob/master/gae/model.py\"\"\"\n",
    "\n",
    "    def __init__(self, dropout, activation=torch.sigmoid):\n",
    "        super(InnerProductDecoder, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = F.dropout(z, self.dropout, training=self.training)\n",
    "        adj = self.act(torch.mm(z, z.t()))\n",
    "        return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(preds, labels, mu, logvar, n_nodes, norm, pos_weight):\n",
    "    cost = norm * F.binary_cross_entropy_with_logits(preds, labels, pos_weight=pos_weight)\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 / n_nodes * torch.mean(torch.sum(\n",
    "        1 + 2 * logvar - mu.pow(2) - logvar.exp().pow(2), 1))\n",
    "    return cost + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of adjacency matrix:  (2708, 2708)\n",
      "Length of features:  2708\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get adjacency matrix and various edge lists \n",
    "\n",
    "features = torch.FloatTensor(np.array(data['x']))\n",
    "\n",
    "n_nodes, feat_dim = features.shape\n",
    "\n",
    "edgeList = np.array(data['edge_index'].transpose(1,0 ))\n",
    "adj = nx.adjacency_matrix(nx.from_edgelist(edgeList))\n",
    "\n",
    "print('Shape of adjacency matrix: ', adj.shape)\n",
    "print('Length of features: ', len(features))\n",
    "\n",
    "def sparse_to_tuple(sparse_mx):\n",
    "    sparse_mx = sparse_mx.tocoo()\n",
    "        \n",
    "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
    "    values = sparse_mx.data\n",
    "    shape = sparse_mx.shape\n",
    "    return coords, values, shape\n",
    "\n",
    "adj = adj - sp.sparse.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape =adj.shape)\n",
    "adj.eliminate_zeros()\n",
    "\n",
    "assert np.diag(adj.todense()).sum() == 0\n",
    "\n",
    "adj_triu = sp.sparse.triu(adj)\n",
    "adj_tuple = sparse_to_tuple(adj_triu)\n",
    "\n",
    "edges = adj_tuple[0]\n",
    "edges_all = sparse_to_tuple(adj)[0]\n",
    "all_edge_idx = list(range(edges.shape[0]))\n",
    "\n",
    "adj_train = adj[data['train_mask']]\n",
    "\n",
    "train_edges = edgeList \n",
    "\n",
    "train_mask_indices = [i for i, x in enumerate(data['train_mask']) if x]\n",
    "valid_mask_indices = [i for i, x in enumerate(data['val_mask']) if x]\n",
    "test_mask_indices = [i for i, x in enumerate(data['test_mask']) if x]\n",
    "\n",
    "train_edges = adj_train[train_mask_indices]\n",
    "valid_edges = adj_train[valid_mask_indices]\n",
    "test_edges = adj_train[test_mask_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess graph\n",
    "\n",
    "def preprocess_graph(adj):\n",
    "    adj = sp.sparse.coo_matrix(adj)\n",
    "    adj_ = adj + sp.eye(adj.shape[0])\n",
    "    rowsum = np.array(adj_.sum(1))\n",
    "    degree_mat_inv_sqrt = sp.sparse.diags(np.power(rowsum, -0.5).flatten())\n",
    "    adj_normalized = adj_.dot(degree_mat_inv_sqrt).transpose().dot(degree_mat_inv_sqrt).tocoo()\n",
    "    # return sparse_to_tuple(adj_normalized)\n",
    "    return sparse_mx_to_torch_sparse_tensor(adj_normalized)\n",
    "\n",
    "adj_norm = preprocess_graph(adj)\n",
    "adj_label = adj_train + sp.eye(adj_train.shape[0])\n",
    "adj_label = torch.FloatTensor(adj_label.toarray())\n",
    "pos_weight = float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
    "\n",
    "norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
    "hidden_emb = None \n",
    "\n",
    "\n",
    "model = VAE(data.num_features, 32, 16, dropout=0)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model, data = VAE().to(device), data.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    recovered, mu, logvar = model(features, adjnorm)\n",
    "    loss = loss_function(recovered, adj_label, mu, logvar, n_nodes, norm, pos_weight)\n",
    "    \n",
    "    loss.backward()\n",
    "    cur_loss = loss.item()\n",
    "    optimizer.step()\n",
    "    \n",
    "    hidden_emb = mu.data.numpy()\n",
    "    roc_curr, ap_curr = get_roc_score(hidden_emb, adj_orig, val_edges, val_edges_false)\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(cur_loss),\n",
    "          \"val_ap=\", \"{:.5f}\".format(ap_curr),\n",
    "          \"time=\", \"{:.5f}\".format(time.time() - t)\n",
    "          )\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "roc_score, ap_score = get_roc_score(hidden_emb, adj_orig, test_edges, test_edges_false)\n",
    "print('Test ROC score: ' + str(roc_score))\n",
    "print('Test AP score: ' + str(ap_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train():\n",
    "#     model.train()\n",
    "#     optimizer.zero_grad()\n",
    "#     F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "\n",
    "# def test():\n",
    "#     model.eval()\n",
    "#     logits, accs = model(), []\n",
    "#     for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "#         pred = logits[mask].max(1)[1]\n",
    "#         acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
    "#         accs.append(acc)\n",
    "#     return accs\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    logits, accs = model(), []\n",
    "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "        pred = logits[mask].max(1)[1]\n",
    "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
    "        accs.append(acc)\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-282276b2c2a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbest_val_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmp_test_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbest_val_acc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-94-caadce55e890>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lab\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-92-9383750808b1>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[0mz_loc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_scale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_loc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-92-9383750808b1>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m#         return F.log_softmax(x, dim=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftplus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mz_loc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgc2_mu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mz_scale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgc2_sig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "best_val_acc = test_acc = 0\n",
    "for epoch in range(1, 100):\n",
    "    train()\n",
    "    train_acc, val_acc, tmp_test_acc = test()\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        test_acc = tmp_test_acc\n",
    "    log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
    "    print(log.format(epoch, train_acc, best_val_acc, test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser(description=\"parse args\")\n",
    "# parser.add_argument('-n', '--num-epochs', default=2, type=int, help='number of training epochs')\n",
    "# parser.add_argument('-tf', '--test-frequency', default=5, type=int, help='how often we evaluate the test set')\n",
    "# parser.add_argument('-lr', '--learning-rate', default=2.0e-3, type=float, help='learning rate')\n",
    "    \n",
    "# parser.add_argument('--cuda', action='store_true', default=False, help='whether to use cuda')\n",
    "# parser.add_argument('--jit', action='store_true', default=False, help='whether to use PyTorch jit')\n",
    "# parser.add_argument('-visdom', '--visdom_flag', action=\"store_true\", help='Whether plotting in visdom is desired')\n",
    "# parser.add_argument('--time', default=int(time.time()), help=\"Current system time\")\n",
    "\n",
    "# parser.add_argument('--name', default='Mnist', help=\"Name of the dataset\")\n",
    "# parser.add_argument('--save', default=False, help=\"Whether to save the trained model\")\n",
    "# args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([3, 4, 4, 0, 3, 2, 0, 3, 3, 2, 0, 0, 4, 3, 3, 3, 2, 3, 1, 3, 5, 3, 4, 6,\n",
      "        3, 3, 6, 3, 2, 4, 3, 6, 0, 4, 2, 0, 1, 5, 4, 4, 3, 6, 6, 4, 3, 3, 2, 5,\n",
      "        3, 4, 5, 3, 0, 2, 1, 4, 6, 3, 2, 2, 0, 0, 0, 4, 2, 0, 4, 5, 2, 6, 5, 2,\n",
      "        2, 2, 0, 4, 5, 6, 4, 0, 0, 0, 4, 2, 4, 1, 4, 6, 0, 4, 2, 4, 6, 6, 0, 0,\n",
      "        6, 5, 0, 6, 0, 2, 1, 1, 1, 2, 6, 5, 6, 1, 2, 2, 1, 5, 5, 5, 6, 5, 6, 5,\n",
      "        5, 1, 6, 6, 1, 5, 1, 6, 5, 5, 5, 1, 5, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(data.train_mask)\n",
    "print(data.y[data.train_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
