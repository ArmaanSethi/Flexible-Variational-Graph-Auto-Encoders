{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid, MNISTSuperpixels\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, ChebConv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Mnist'\n",
    "path = '../data/geometric/MNIST'\n",
    "dataset = MNISTSuperpixels(path, dataset, T.Distance())\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "# dataset = Planetoid(path, dataset, T.NormalizeFeatures())\n",
    "#data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(dataset.num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = GCNConv(dataset.num_features, 16, improved=False)\n",
    "#         self.conv2 = GCNConv(16, dataset.num_classes, improved=False)\n",
    "#         # self.conv1 = ChebConv(data.num_features, 16, K=2)\n",
    "#         # self.conv2 = ChebConv(16, data.num_features, K=2)\n",
    "        \n",
    "#     def forward(self):\n",
    "#         x, edge_index = data.x, data.edge_index\n",
    "#         x = F.relu(self.conv1(x, edge_index))\n",
    "#         x = F.dropout(x, training=self.training)\n",
    "#         x = self.conv2(x, edge_index)\n",
    "#         return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_features, 16, improved=False)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes, improved=False)\n",
    "        # self.conv1 = ChebConv(data.num_features, 16, K=2)\n",
    "        # self.conv2 = ChebConv(16, data.num_features, K=2)\n",
    "        \n",
    "        self.deconv1 = GCNConv(dataset.num_classes, 16, improved=False)\n",
    "        self.deconv2 = GCNConv(16, dataset.num_features, improved=False)\n",
    "        \n",
    "    def encode(self, x, edge_index):\n",
    "        \n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return x, edge_index\n",
    "    \n",
    "    def decode(self, x, edge_index):\n",
    "        x = F.relu(self.deconv1(x, edge_index))\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        x = self.deconv2(x, edge_index)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        \n",
    "    def forward(self):\n",
    "        \n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        encoded, idx = self.encode(x, edge_index)\n",
    "        decoded = self.decode(encoded, idx)\n",
    "        \n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "numEpochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 train loss:  0.19061681628227234\n",
      "Epoch:  1 train loss:  0.15084707736968994\n",
      "Epoch:  1 train loss:  0.13869276642799377\n",
      "Epoch:  1 train loss:  0.12381277233362198\n",
      "Epoch:  1 train loss:  0.12354801595211029\n",
      "Epoch:  1 train loss:  0.11772618442773819\n",
      "Epoch:  1 train loss:  0.10465120524168015\n",
      "Epoch:  1 train loss:  0.09563049674034119\n",
      "Epoch:  1 train loss:  0.09878691285848618\n",
      "Epoch:  1 train loss:  0.10717673599720001\n",
      "Epoch:  1 train loss:  0.11034782975912094\n",
      "Epoch:  1 train loss:  0.11038356274366379\n",
      "Epoch:  1 train loss:  0.11148583889007568\n",
      "Epoch:  1 train loss:  0.10845232754945755\n",
      "Epoch:  1 train loss:  0.10239468514919281\n",
      "Epoch:  1 train loss:  0.09956809133291245\n",
      "Epoch:  1 train loss:  0.10118277370929718\n",
      "Epoch:  1 train loss:  0.09562849253416061\n",
      "Epoch:  1 train loss:  0.10060091316699982\n",
      "Epoch:  1 train loss:  0.10658057779073715\n",
      "Epoch:  2 train loss:  0.09860781580209732\n",
      "Epoch:  2 train loss:  0.10430910438299179\n",
      "Epoch:  2 train loss:  0.10513541102409363\n",
      "Epoch:  2 train loss:  0.10030695050954819\n",
      "Epoch:  2 train loss:  0.10070017725229263\n",
      "Epoch:  2 train loss:  0.09722056239843369\n",
      "Epoch:  2 train loss:  0.10215423256158829\n",
      "Epoch:  2 train loss:  0.10062025487422943\n",
      "Epoch:  2 train loss:  0.09868777543306351\n",
      "Epoch:  2 train loss:  0.0963493213057518\n",
      "Epoch:  2 train loss:  0.0975039079785347\n",
      "Epoch:  2 train loss:  0.0983876958489418\n",
      "Epoch:  2 train loss:  0.09737478941679001\n",
      "Epoch:  2 train loss:  0.09401394426822662\n",
      "Epoch:  2 train loss:  0.09765169024467468\n",
      "Epoch:  2 train loss:  0.10128262639045715\n",
      "Epoch:  2 train loss:  0.0967119038105011\n",
      "Epoch:  2 train loss:  0.09516351670026779\n",
      "Epoch:  2 train loss:  0.09265974909067154\n",
      "Epoch:  2 train loss:  0.09579945355653763\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, numEpochs+1):\n",
    "    for step, batch in enumerate(loader):\n",
    "        if step < 20:\n",
    "            \n",
    "            data = batch.to(device)\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = nn.MSELoss()\n",
    "            target = data\n",
    "            \n",
    "#             print(target['x'])\n",
    "#             print(model())\n",
    "            \n",
    "            output = loss(model(), target['x'])\n",
    "            output.backward()\n",
    "\n",
    "\n",
    "#             F.binary_cross_entropy(model(), target['x']).backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "\n",
    "            print('Epoch: ', epoch, 'train loss: ', output.item())\n",
    "        else: \n",
    "            break\n",
    "    \n",
    "\n",
    "#             # plotting decoded image (second row)\n",
    "#             _, decoded_data = autoencoder(view_data)\n",
    "#             for i in range(N_TEST_IMG):\n",
    "#                 a[1][i].clear()\n",
    "#                 a[1][i].imshow(np.reshape(decoded_data.data.numpy()[i], (28, 28)), cmap='gray')\n",
    "#                 a[1][i].set_xticks(()); a[1][i].set_yticks(())\n",
    "#             plt.draw(); plt.pause(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train():\n",
    "#     model.train()\n",
    "#     optimizer.zero_grad()\n",
    "    \n",
    "#     F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()\n",
    "    \n",
    "#     loss = nn.BCELoss()\n",
    "#     target = data.x[data.train_mask]\n",
    "#     print(target)\n",
    "#     print(model()[data.train_mask])\n",
    "    \n",
    "#     output = loss(model()[data.train_mask], target)\n",
    "#     output.backward()\n",
    "    \n",
    "    \n",
    "#     torch.nn.BCELoss(model()[data.train_mask], data.x[data.train_mask]).backward()\n",
    "    \n",
    "#     optimizer.step()\n",
    "\n",
    "# def test():\n",
    "#     model.eval()\n",
    "#     logits, accs = model(), []\n",
    "#     for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "#         pred = logits[mask].max(1)[1]\n",
    "#         acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
    "#         accs.append(acc)\n",
    "#     return accs\n",
    "\n",
    "# best_val_acc = test_acc = 0\n",
    "# for epoch in range(1, 50):\n",
    "#     train()\n",
    "#     train_acc, val_acc, tmp_test_acc = test()\n",
    "#     if val_acc > best_val_acc:\n",
    "#         best_val_acc = val_acc\n",
    "#         test_acc = tmp_test_acc\n",
    "#     log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
    "#     print(log.format(epoch, train_acc, best_val_acc, test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
